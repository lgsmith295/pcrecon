---
title: 'pcrecon: An R Package for Nested Principal Component Regression Climate Reconstructions'
author: Laura Smith^1^\*, Nicholas Nagle^1^, Stockton Maxwell^2^, Daniel Hocking^1
output:
  word_document:
    reference_docx: template.docx
  pdf_document: default
bibliography: Bibliography.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE, message = FALSE, warning = FALSE)

```

```{r setup}
#devtools::install_github("lgsmith295/pcrecon")
library(pcrecon)
```

*^1^ University of Tennessee; Knoxville, Tennessee, USA*
*^2^ Radford University; Radford, Virginia, USA*
*^3^ NOAA Greater Atlantic Regional Fisheries Office, Gloucester, MA, USA*

*\* Corresponding Author Email: lsmit224@vols.utk.edu*

# Abstract
We present pcrecon, a new software package in R for the development of nested principal component regression climate reconstructions from tree ring data in R. This package duplicates and extends the well known Fortran program PCreg. The use of the R statistical programming environment for this application can improve replicability and transparency of climate reconstructions, which are both crucial to the goals of the paleoclimate community. 

# Introduction

## Climate Reconstructions and Principal Component Regression

Climate reconstructions from tree-ring records are based on the statistical relationship between a target climate variable one or more nearby tree ring chronologies as estimated using linear regression. Model coefficients are calculated for the period of time over which the tree ring data and climate data overlap, usually around 80-100 years, then predictions are made for years that predate the instrumental climate based on the tree rings. Tree-ring records from multiple species and locations within a region are often used to fit the model, particularly for reconstructions in temperate climate regions where the relationships between tree growth and climate is complex [@Cook1999].  This can help to parse the local, autocorrelated ecological noise related to forest succession, competition, and disturbance from desired regional climate signal. A common problem with multiple regression methods is that many independent variables can produce models which are overfit or that suffer from issues related to multicollinearity. Principal Component Analysis (PCA) and Principal Component Regression (PCR) are widely used to address these issues by reducing the dimensionality of tree-ring predictor variables[@jacoby_past_1981;@Briffa1983; @Cook1999; @williams_large_2020]. PCR has been of particular importance in reconstructing climate of the eastern U.S., where climate-growth relationships are more complex due to the temperate climate and highly disturbed forests [@Harley2017; @Maxwell2011; @Maxwell2017]

A limitation of PCA is that it requires that data vectors to be of equal length. Because tree-ring records vary significantly in their length,a nesting technique is applied. First, the period of time over which all chronologies overlap is determined, this is called the 'common period'. PCA eigenvectors and linear regression estimates are calculated for that time period only. The shortest chronology is then dropped from the analysis, and the next common period is determined, and so on, such that a new regression model and predictions are calculated for each common period. These nests are then spliced together to form a long-running reconstruction which has an estimate value for each year that there are tree ring data available. 

Data are held out from the model calibration to validate the estimates. Common validation statistics are Reduction of Error (RE) and Coefficient of Efficiency (CE) and $$r^2$$. $$r^2$$ is commonly defined as the variance explained by the model. $$RE$$ compares the model mean square error (MSE) is to the calibration mean and provides a metric of how predictive the model compared to the mean. A value greater than 0 indicates that the model is better than the calibration mean at predicting values. $$CE$$ is similar, but compares the MSE to the held out validation period values, making it a stricter test [@noauthor_surface_2006]

Many researchers rely on specialized FORTRAN based software program called PCreg (https://www.ldeo.columbia.edu/tree-ring-laboratory/resources/software) to perform these procedures. This software can be used to filter tree ring data by location, summarize and prewhiten climate data, determine common periods, make estimates, and calculate validation statistics. We introduce an R package, pcrecon, which can perform many of the same functions and numerically replicate results from PCreg. We propose that the R environment improves replicability and transparency in addition to streamlining the workflow of performing these reconstructions. 

## Software for Analysis of Paleoclimate Proxy Data
Due to the labor-intensive nature of data collection and the specialized statistical methods used for the analysis of tree-ring data, the paleoclimate community encourages the open sharing of data and software. This is evidenced by the popularity and frequent use of resources such as the International Tree Ring Data Bank (ITRDB, NOAA), the Dendrochronology Program Library (Richard Holmes/University of Arizona), the Lamont-Doherty dendrochronology software repository (https://www.ldeo.columbia.edu/tree-ring-laboratory/resources/software), and R packages such as dplR [@Bunn2008] and treeclim [@Zang2015]. 

Incredible efforts have been made over the last 40 years in the development of statistical techniques for tree-ring data analysis and associated software which allow users to standardize tree-ring series, develop chronologies, cross-date, correlate to climate field, estimate climate reconstructions, and more. These software tools revolutionized dendrochronology, and their free availability to the community is a testament to the importance of open communication and collaboration in science. Many of these programs utilize an interactive user interface and are based in FORTRAN, which is a powerful and versatile language well suited to scientific computing. They efficiently perform complex calculations, preventing the user from having to program them.

PcReg has become the standard for many researchers seeking to estimate past climates from tree rings using PCR. Like other programs designed for tree-ring analysis (ARSTAN, COFECHA, EDRM), PcReg handles the legacy fixed-width formats (i.e. Tuscon and chronology formats) that are commonly used to store tree-ring data, but is not otherwise flexible in how the data areformatted. The current publicly available version of PCreg requires users to run each individual nest separately and splice them together. This process is time consuming and creates the potential for human error. The compiled nature of the program does not allow for users to visualize data, perform transformations, check residuals of liner regressions, or other steps that are typically part of the process of statistical analysis. This encourages poor practice, especially among new users or those who are not trained in data analysis.

## R Environment 
R is a powerful statistical programming language and software environment which has several advantages over common FORTRAN or MATLAB based programs. Unlike Matlab, R is free and open source, in addition to being extremely versatile in its application for many different types of statistical analyses, data processing, visualization, etc. In comparison to Fortran, R is an interactive programming language, easier to use and develop in, widely taught in graduate programs, and there are large numbers of online learning resources. It has a large global user-base across a wide variety of disciplines, many of whom are actively engaged in various wikis, newsletters, and web forums (such as stack exchange). This create a community of support through active dialogue and problem solving. 

In contrast to the commonly used FORTRAN programs for tree-ring analysis, R utilizes the command-line rather than an interactive user interface. On its surface, this may seem like a disadvantage to some users. However, most common tree-ring packages in R are well-documented with vignettes that provide worked examples. There are great workflow advantages in having repeatable scripts that can be adjusted and rerun all within R, without having to open a separate text file, close and reopen a program file, and re-run log files. It's also simple to reorganize and do any number of manipulations to the data (i.e. filtering, transformations, etc), as well as many types of analyses (tree-ring specific or not), and produce publication quality visualizations, all in one software environment. Thanks to the work of Andy Bunn and others on package dplR (2012), fixed width format files can be read into R, making all manner of analysis on these data more accessible.  

The implications for reproducibility in using script-based code are perhaps the most important aspect. Peer-reviewed journals are increasingly requiring data and analysis to be provided as part of the manuscript submission. This is not feasible with the many output files that are rendered in programs like PCreg or ARSTAN, and the outputs are not universally very readable outside of those individuals who work with them frequently. A standard, versatile, common, and cross-disciplinary environment for analysis is important for clear communication and reproducibility of results, as well as collaborations with subject matter experts in other fields. 

In the case of PcReg, while the methods are well-documented in a number of publications, there is no documentation for the use of the program. The interactive interface is not intuitive, therefore its use has become something of an oral tradition, where an experienced researchers share how to use the program through workshops or individual interactions. While there is nothing inherently wrong with this approach, the strict documentation requirements for inclusion in the CRAN repository are an additional advantage of working within the R environment.


# Pcrecon Package

## Installation

The current version of pcrecon can be downloaded using the `install_github()` function in the devtools packages:

`> devtools::install_github("lgsmith295/pcrecon")`

## Citation

When using the nested PCR methods for tree ring reconstructions, please cite Ed Cook's work on the North American Drought Atlas:

Cook, E. R., Meko, D. M., Stahle, D. W., & Cleaveland, M. K. (1999). Drought reconstructions for the continental United States. Journal of Climate, 12(4), 1145-1162.

If using this package to perform those procedures, also cite:

Laura Smith, Daniel Hocking and Nicholas Nagle (2020). pcrecon: Principal Component Regression for Dendroclimatology. R package version 0.1.0.

## Functions

There are three main functions in the pcreg package for making reconstruction estimates: load_clim(), eval_clim() and pcreg().

`load_clim()` takes monthly climate data and selects individual months, averages, or sums across selected months (previous year through current year, -12:12). Input is a dataframe or matrix object containing climate data, months of interest, and method for summarizing. Output is an S3 list which includes the climate variable and the ar model if prewhitening is indicated.

`eval_clim` selects chronologies for inclusion in the PC regression based on correlation with the climate variable. Inputs are the S3 list as created by the load_clim() function and a dataframe containing tree-ring chronology data in which each column is a chronology. Output includes a dataframe of correlation coefficients for each chronology and the target climate variable, a dataframe of chronologies selected for inclusion in the model, and a dataframe containing the start and end year of each selected chronology.

`pcreg()` calculates principal component eigenvectors and linear regression model estimates, then makes predictions for each nest and splices them together. Output includes: climate reconstruction, model statistics and validation statistics for each nest, PCA objects for each nest, and lm objects for each nest.  

Additional functions are used to retrieve metadata from ITRDB downloaded tree ring files, filter tree rings for inclusion based on spatial location or correlation to target climate, and to upload and summarize climate data from various formats. An example of the workflow using pcrecon is provided below.

# Worked Example
## Data
Tree ring data downloaded form the ITRDB using the FedData package (include code to procure? used a bounding box)
Climate data is USGS Streamflow gage data for gauge #347432, downloaded from waterdata.usgs.gov


```{r}
#install.packages("remotes")
#remotes::install_github("lgsmith295/pcrecon", build_vignettes = FALSE)
library(remotes)
library(pcrecon)
library(dplyr)
library(ggplot2)
library(flextable)
```

Streamflow data from gauge 08380500 (Gallinas Creek near Montezuma), Latitude 35°39'07.18", Longitude 105°19'07.79"


![Location of Stream gauge on Gallinas Creek near Montezuma]("earthmap_example.jpg")   




Tree ring data from ITRDB

![Bounding Box for retrieving ITRDB tree ring chronologies]("bb.png")

## Code
Typical workflow for this type of analysis often begins with downloading proxy data from a repository, or uploading the users own data. Tree ring data downloaded from the ITRDB is accompanied by a folder of metadata files in JavaScript Object Notation (JSON) format. The `parse_json()` function can be used to creates a table which includes: lat/lon, chronology length, species, elevation, and NOAA ID for each chronology. The user indicates the directory location for the folder containing the .json files using the "dir" argument. When center = TRUE, the mean between the minimum/maximum elevation, northernmost/southernmost latitude, and easternmost/westernmost longitude is reported.

'> metadata <- parse_json(dir = "extdata/metadata", center = TRUE)

```{r, include= TRUE}


metadata <- parse_json(dir = system.file("extdata/metadata", package = "pcrecon", mustWork = TRUE), center = TRUE)

metadata_clean <- metadata %>%
  dplyr::select(-c("coreLengthMeters", "earliestYearCE", "mostRecentYearCE", "earliestYearBP", "mostRecentYearBP"))

metadata_sm <- autofit(fontsize(flextable(metadata_clean[1:15,]), size = 8, part = "all"))


metadata_sm <- metadata_clean[1:15,]

print(metadata_sm)

metadata_sm

```

Having these metadata in a table allows the user to filter based on variables such as location, species, elevation, etc. The pcrecon package contains two functions for filtering chronologies or other datasets based on spatial location. The first, `filter_rad()`, selects chronology IDs that fall within a given radius from a point. The arguments for this function are: dataframe containing site ID, latitude, and longitude, the lat/lon of the center point, and the radius in km. The output of this function is a character vector of chronology IDs that fall within that radius.

Here, we will filter within a 150km radius of the streamgauge, and save the output as an object called select_crns_rad.

`> select_crns_rad <- filter_rad(x = metadata, cent_lat = 35.65, cent_lon = -105.32, radius = 150, plot = TRUE)'

```{r, include = TRUE}

select_crns_rad <- filter_rad(x = metadata, cent_lat = 35.65, cent_lon = -105.32, radius = 150, plot = TRUE)

```


Another option for filtering chronologies spatially is to select those within a given climate footprint using the `filter_foot()` function. This method is most often used when reconstructing streamflow. Chronologies are selected within an area where the correlation (r) between streamflow and precipitation or soil moisture meets a given threshhold [@Maxwell2017]. This function requires a raster file. In this example, a .nc file created in the KNMI climate explorer (https://climexp.knmi.nl/start.cgi) is used, which contains correlation coefficients between PRISM 4km gridcell precipitation data (PRISM Climate Group, 2004) and Gallinas Creek streamflow.

We will select chronologies that are in an area where correlation between streamflow and precipitation is 0.5 or higher (r = 0.5). Often a lower threshold of .3 is used, for the purpose of keeping the example dataset small we use a more strict cutoff.


```{r}
footprint <- raster::raster(system.file("extdata/gallinas_cf.nc", package = "pcrecon", mustWork = TRUE))

  

```

`> footprint <- raster::raster(system.file("extdata/gallinas_cf.nc", package = "pcrecon", mustWork = TRUE))`
`> select_crns_fp <- filter_foot(x = metadata, footprint = footprint, r = 0.5, cent_lat = 35.65, cent_lon = -105.32, radius = 150, plot = TRUE)`



```{r, include = TRUE}
select_crns_fp <- filter_foot(x = metadata, footprint = footprint, r = 0.5, cent_lat = 35.65, cent_lon = -105.32, radius = 300, plot = TRUE)

```
Those tree ring records (circles) that fall within the black polygon are included, anything in the red polygon would not have been included. The radius and center point arguments in this function allow the user to designate a radius that polygon must intersect with (not fall completely within), in order to prevent tree rings in locations with spurious correlations that are outside a reasonable distance to be included in anaylsis. 

filter_foot and filter_rad return a character vector containing IDs of the chronologies that should be included in the next step of the analysis. The load_crns function reads those .crn files from a folder, such as those downloaded from the ITRDB or produced using dplR or ARSTAN. The user can select which measurement and chronology types associated with each ID to read in. The default is the standard ring width chronology. Other options include:

   Code Measurement Type (`type_measure`)
   
   D Total Ring Density
   E Earlywood Width
   I Earlywood Density
   L Latewood Width
   N Minimum Density
   R Ring Width
   T Latewood Density
   X Maximum Density
   P Latewood Percent
    Code Chronology Type (`type_crn`)
   A ARSTND
   P Low Pass Filter
   R Residual
   S Standard
   W Re-Whitened Residual
   N Measurements Only
    
 The output is a dataframe in which columns contain chronologies and rows are ring width observations 

```{r, include = TRUE}
crns_df <- load_crns(dir = system.file("extdata/crns", package = "pcrecon", mustWork = TRUE), crns = select_crns_fp)
crns_df <- dplyr::arrange(crns_df, year)

crns_df_sm <- autofit(fontsize(flextable(crns_df[800:803,]), size = 8, part = "all"))

crns_df_sm

```

Climate data can be read in from any file format using base R functions.From here, data can be checked for skewness, transformed, reformatted, checked for missing values and autocorrelation, etc.

```{r}

# 13 column format with renamed columns
data("gallinas_flow")
names(gallinas_flow) <- c("year", 1:12)

# long format
climate_long <- gallinas_flow %>%
  tidyr::pivot_longer(2:13, names_to = "month", values_to = "value")

ggplot(data = climate_long, aes(x = value)) + geom_histogram()

ar(climate_long$value)
```

```{r}

climate_long$value <- log(climate_long$value)

ggplot(data = climate_long, aes(x = value)) + geom_histogram()


ar(climate_long$value)

```

The load_clim function aggregates the climate by calculating the mean or sum over particular months of interest. You can also select individual months. This function requires that these data be in 13 column (year and months 1:12) or long (3 column - "ID", "month", and "value") format. 


`>climate <- load_clim(clim = climate_long, mos = c(4:7), method = "mean", prewhiten_clim = FALSE)`
`> ar(climate$clim_small$values)`

```{r, include = TRUE}
climate <- load_clim(clim = climate_long, mos = c(4:7), method = "mean", prewhiten_clim = FALSE)

```

eval_clim() calculates correlations between the climate variable and the chronologies. Here, the user indicates the calibration/validation period for the intended model, the window over which to correlate the chronologies and climate, leads/lags, correlation test type, confidence value, and a correlation cutoff for selecting chronologies. Weighting features will be added later. See function documentation for options.

`>data_obj_pw <- eval_clim(crns = crns_df, lead = 0, prewhiten_crn = TRUE, climate = climate, calib = 1950:1968, valid = 1927:1949, cor_window = "calib", type = "pearson", alternative = "two.sided", r = -1, conf = 0.90, print = TRUE, out_fmt = "csv", out_dir = "test/", pr_years = NULL)`

```{r}
data_obj_pw <- eval_clim(crns = crns_df, lead = 1, prewhiten_crn = TRUE, climate = climate, calib = 1950:1968, valid = 1927:1949, cor_window = "calib", type = "pearson", alternative = "two.sided", r = -1, conf = 0.90, print = TRUE, out_fmt = "csv", out_dir = "test/", pr_years = NULL)
```



```{r}
data_obj <- eval_clim(crns = crns_df, lead = 0, prewhiten_crn = FALSE, climate = climate, calib = 1950:1968, valid = 1927:1949, cor_window = "calib", type = "pearson", alternative = "two.sided", r = -1, conf = 0.90, print = TRUE, out_fmt = "csv", out_dir = "test/", pr_years = NULL)
```

The output of eval_clim() is an S3 object of class "PCreg_data". This object contains lots of necessary pieces that feed into the final regression model function. You can view the the components of the object using the "$" operator:

`>data_obj$cors_table` table of all cross correlations`
`>data_obj$cors_table_small` table of selected chronology correlatons`
`>data_obj$nests` beginning and end year for each nest
`>data_obj$clim_ar` autoregressive model selected for climate`

```{r, include = TRUE}
class(data_obj)

cors_table <- data_obj_pw$cors_table #table of all cross correlations
cors_table_small <- data_obj_pw$cors_table_small #table of selected chronology correlatons
nests <- data_obj_pw$nests 
clim_ar <- data_obj_pw$clim_ar #autoregressive model selected for climate


autofit(fontsize(flextable(cors_table), size = 8, part = "all"))
autofit(fontsize(flextable(cors_table_small), size = 8, part = "all"))
autofit(fontsize(flextable(nests), size = 8, part = "all"))




```



The pcreg() function takes the information from the previous step ,in the form of the PCreg_data object, and performs the principal component regression estimates for each nest. The user indicates the selection threshold for PCs, the window over which to calculate PCs, and the window over which to scale the variance. 

`>recon <- pcreg(data = data_obj, pc_calc = "calib", select_pc = "eigenvalue1", scale_var = "calib", plot = TRUE, weight = NULL, cum_perc = NULL)`

```{r, include = TRUE}
pw_recon <- pcreg(data = data_obj_pw, pc_calc = "calib", select_pc = "eigenvalue1", scale_var = "calib", plot = TRUE, weight = NULL, cum_perc = NULL)

pw_recon$plot
```

```{r}
recon <- pcreg(data = data_obj, pc_calc = "calib", select_pc = "eigenvalue1", scale_var = "calib", plot = TRUE, weight = NULL, cum_perc = NULL)

recon$plot

```

The output of this function is an object of class PCreg_recon, and you can call the pieces of it as was done above. Output reconstruction estimates, validation and calibration period statistics (RE, CE, R2), as well as linear model and Principal Component Analysis objects for each nest and autoregressive model statistics for climate and chronologies if AR prewhitening is used.


`>recon$model_stats`  linear regression model statistics`
`>recon$calibration_stats` calibration period statistics`
`>recon$validation_stats` validation period statistics`

```{r, include = TRUE}

model_tbl <- pw_recon$model_stats # linear regression model statistics
calib_tbl <- pw_recon$calibration_stats #calibration period statistics
valid_tbl <- pw_recon$validation_stats #validation period statistic


autofit(fontsize(flextable(model_tbl), size = 8, part = "all"))
autofit(fontsize(flextable(calib_tbl), size = 8, part = "all"))
autofit(fontsize(flextable(valid_tbl), size = 8, part = "all"))
```



# Comparison to PCreg

When autoregressive prewhitening is not used, pcrecon perfectly replicates the results of PCreg:

```{r, include = TRUE}
pcreg <- read.csv("../inst/extdata/pcreg_recon.csv")



pcrecon <- recon$recon %>%  dplyr::filter(year %in% c(1690:1968))
pw <- pw_recon$recon %>% dplyr::filter(year %in% c(1690:1968))
pw_fit <- pw$fit

df <- cbind(pcrecon, pcreg, pw_fit) %>% dplyr::select(-year)


scatterplot <- ggplot(data = df, aes(x = pw_fit, y = pw_crns)) + geom_point() + labs(title = "1690-1968 nest, pcrecon vs PCreg output", x = "pcrecon output", y = "PCreg output") + geom_abline(intercept = 0, slope = 1, color = "blue")

ggsave("pw_scatter.tif", scatterplot, device = "tiff", dpi = 600)


```

While the process of prewhitening is identical  between the two programs, the period of time over which the AR model is estimated varies. PCreg requires the user identify a period within each nest to calculate the autoregressive model coefficients, whereas in pcrecon, we use the entire length of the chronology. This produces very similar results that ($$r^2$$ = .994) that fall well within the bounds of uncertainty for these types of models. 

```{r, include = TRUE}
ggplot(data = df, aes(x = pw_fit, y = pw_crns)) + geom_point() + labs(title = "1690-1968 nest, pcrecon vs PCreg output", x = "pcrecon output", y = "PCreg output") + geom_abline(intercept = 0, slope = 1, color = "blue")


mod <- lm(pw_fit~pw_crns, data = df)
summary(mod)

```

# Citations
PRISM Climate Group, Oregon State University, http://prism.oregonstate.edu, created 4 Feb 2004.
