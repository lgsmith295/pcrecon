---
title: "Example Walkthrough"
author: "Laura Smith"
date: "8/31/2020"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---






```{r}
#install.packages("remotes")
#remotes::install_github("lgsmith295/pcrecon", build_vignettes = FALSE)
library(remotes)
library(pcreg)
library(dplyr)
library(ggplot2)
```

Streamflow data from gauge 08380500 (Gallinas Creek near Montezuma), Latitude 35°39'07.18", Longitude 105°19'07.79"


![Location of Stream gauge on Gallinas Creek near Montezuma]("earthmap_example.jpg")   




Tree ring data from ITRDB

![Bounding Box for retrieving ITRDB tree ring chronologies]("bb.png")


The first helpful function if you've downloaded tree ring data from the ITRDB is parse_json(), which creates a table from JSON metadata files. You will need to indicate the directory location for the folder containing the .json metadata files using the dir = argument. When center = TRUE, the mean between the minimum/maximum elevation, northernmost/southernmost latitude, and easternmost/westernmost longitude is reported. The output for this function is a dataframe.

```{r}
metadata_full <- parse_json(dir = system.file("extdata/metadata", package = "pcreg", mustWork = TRUE), center = TRUE)

metadata_full

```

This allows you to do a bulk download of data, then filter based on variables you might care about for your study, such as species, elevation, chronology length, etc. We will filter these data to make sure that we don't include any datasets that end before 1970 to maximize our calibration/validation periods.

```{r}
metadata <- metadata_full %>% dplyr::filter(mostRecentYearCE > 1970)

```

There are two functions that will filter your chronology based on spatial location. The first filters chronologies based on a radius from a particular point. The inputs are the metadata file with lat/long, the lat/lon of the center point of the radius, and the radius you want to include in km. The output of this function is a list of chronology IDs that fall within that radius

we will filter within a 75km radius of the streamgauge, and save the output as an object called select_crns_rad.

```{r}

select_crns_rad <- filter_rad(x = metadata, cent.lat = 35.65, cent.lon = -105.32, radius = 150, plot = TRUE)

```


The other option for spatial filtering is by using a climate footprint (cite harley, s. maxwell, j. maxwell). This requires a climate footprint spatial data file, in most cases this of correlation between streamflow and some metric of precipitation or soil moisture. 

This example uses a .nc file created in the KNMI climate explorer, https://climexp.knmi.nl/start.cgi. This file can be loaded in using the raster package

```{r}
footprint <- raster::raster(system.file("extdata/gallinas_cf.nc", package = "pcreg", mustWork = TRUE))
  

```

select_crns_fp() filters the tree ring chronologies based on the location within the footprint.

In this example, we select chronologies that are in an area where correlation between streamflow and precipitation is 0.5 or higher (r = 0.5) -* for the sake of keeping things small *


```{r}
select_crns_fp <- filter_foot(x = metadata_full, footprint = footprint, r = 0.5, cent.lat = 35.65, cent.lon = -105.32, radius = 150, plot = TRUE)

```

The load_crns function pulls the chronologies that are selected by the previous spatial filtering functions from the folder where you .crns files are.

```{r}
crns_df <- load_crns(dir = system.file("extdata/crns", package = "pcreg", mustWork = TRUE), crns = select_crns_fp)
crns_df <- dplyr::arrange(crns_df, year)

```

Next, you'll need to bring in the climate data. I've saved the streamflow data I downloaded from https://waterdata.usgs.gov/nwis as a csv file. The load_clim function, which aggregates the climate data based on the months of interest, require that these data be in 13 column or long (3 column) format.

```{r}
climate <- read.csv(system.file("extdata/gallinas_flow.csv", package = "pcreg"))
names(climate) <- c("year", 1:12)
climate_long <- climate %>%
  tidyr::pivot_longer(2:13, names_to = "month", values_to = "value")

ggplot(data = climate_long, aes(x = value)) + geom_histogram()

ar(climate_long$value)
```


log transform
```{r}

climate_long$value <- log(climate_long$value)

ggplot(data = climate_long, aes(x = value)) + geom_histogram()


ar(climate_long$value)

```

load_clim()

```{r}
climate <- load_clim(clim = climate_long, mos = -10:11, method = "mean", prewhiten.clim = TRUE)

ar(climate$clim_small$values)
```

eval_clim() calculates correlations between the climate variable and the chronologies. 
```{r}
data <- eval_clim(crns = crns_df, lead = 1, lag = 1, prewhiten.crn = TRUE, climate = climate, calib = 1945:1972, valid = 1928:1944, cor.window = "calib", type = "pearson", alternative = "two.sided", r = 0.3, alpha = 0.9, print.out = TRUE, save.out = "csv", dir = "test/")
```

pcreg() 
```{r}
recon <- pcreg(data = data, pc.calc = "calib", select.pc = "eigenvalue1", scale.var = "calib", plot = TRUE, weight = NULL, cum.perc = NULL, save.out = "csv", dir = dir)
```

```{r}
recon$model_stats
recon$calibration_stats
recon$validation_stats
data$nests

```

```{r}

reconstruction <- recon$recon %>%
  mutate(recon_exp = exp(fit))

reconstruction <- full_join(reconstruction, climate$clim_small, by = "year")

reconstruction$value <- exp(reconstruction$value)

recon_recent <- reconstruction %>%
  filter(year > 1850)

ggplot(data = reconstruction, aes(x = year, y = recon_exp)) + geom_line() + geom_line(aes(x = year, y = value), color = "blue")

ggplot(data = recon_recent, aes(x = year, y = recon_exp)) + geom_line() + geom_line(aes(x = year, y = value), color = "blue")

```



